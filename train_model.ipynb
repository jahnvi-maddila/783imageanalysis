{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IC Pin Detection Model Training\n",
    "\n",
    "This notebook trains a YOLOv11 model for detecting IC pins and identifying defects.\n",
    "\n",
    "## Overview\n",
    "- **Model**: YOLOv11 (You Only Look Once version 11)\n",
    "- **Task**: Object detection for IC pin analysis\n",
    "- **Classes**: \n",
    "  - `bent`: Bent pins (defective)\n",
    "  - `okay`: Normal pins\n",
    "  - `package`: IC package detection\n",
    "  - `text`: Text regions on IC\n",
    "\n",
    "## Dataset Structure\n",
    "The dataset should follow YOLO format:\n",
    "```\n",
    "783-Pin-Detection/datasets/aug-ic-dataset/\n",
    "\u251c\u2500\u2500 images/\n",
    "\u2502   \u251c\u2500\u2500 train/\n",
    "\u2502   \u2514\u2500\u2500 val/\n",
    "\u2514\u2500\u2500 labels/\n",
    "    \u251c\u2500\u2500 train/\n",
    "    \u2514\u2500\u2500 val/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "First, ensure you have the required packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Uncomment the line below if you need to install ultralytics\n",
    "# !pip install ultralytics opencv-python matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Dataset\n",
    "\n",
    "Let's verify that the dataset exists and check some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "dataset_config = \"dataset.yaml\"\n",
    "train_images_path = Path(\"783-Pin-Detection/datasets/aug-ic-dataset/images/train\")\n",
    "val_images_path = Path(\"783-Pin-Detection/datasets/aug-ic-dataset/images/val\")\n",
    "train_labels_path = Path(\"783-Pin-Detection/datasets/aug-ic-dataset/labels/train\")\n",
    "val_labels_path = Path(\"783-Pin-Detection/datasets/aug-ic-dataset/labels/val\")\n",
    "\n",
    "# Count images and labels\n",
    "train_images = list(train_images_path.glob(\"*.jpg\")) + list(train_images_path.glob(\"*.jpeg\")) + list(train_images_path.glob(\"*.png\"))\n",
    "val_images = list(val_images_path.glob(\"*.jpg\")) + list(val_images_path.glob(\"*.jpeg\")) + list(val_images_path.glob(\"*.png\"))\n",
    "train_labels = list(train_labels_path.glob(\"*.txt\"))\n",
    "val_labels = list(val_labels_path.glob(\"*.txt\"))\n",
    "\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Training labels: {len(train_labels)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")\n",
    "print(f\"Validation labels: {len(val_labels)}\")\n",
    "\n",
    "# Verify dataset config exists\n",
    "if Path(dataset_config).exists():\n",
    "    print(f\"\\n\u2713 Dataset configuration file '{dataset_config}' found\")\n",
    "    with open(dataset_config, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        print(f\"  Classes: {config['names']}\")\n",
    "else:\n",
    "    print(f\"\\n\u2717 Dataset configuration file '{dataset_config}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images\n",
    "\n",
    "Let's look at some sample images from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample training images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img_path in enumerate(train_images[:6]):\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(img_path.name)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize YOLO Model\n",
    "\n",
    "We'll use a pre-trained YOLOv11 model as a starting point for transfer learning.\n",
    "\n",
    "Available model sizes:\n",
    "- `yolo11n.pt` - Nano (smallest, fastest)\n",
    "- `yolo11s.pt` - Small\n",
    "- `yolo11m.pt` - Medium (recommended for good balance)\n",
    "- `yolo11l.pt` - Large\n",
    "- `yolo11x.pt` - Extra Large (largest, most accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model size (change as needed)\n",
    "model_size = \"yolo11m.pt\"  # Medium model - good balance of speed and accuracy\n",
    "\n",
    "# Load the model\n",
    "model = YOLO(model_size)\n",
    "print(f\"Loaded {model_size} model for transfer learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configure Training Parameters\n",
    "\n",
    "Set up the training hyperparameters. You can modify these based on your needs:\n",
    "\n",
    "- **epochs**: Number of training iterations over the entire dataset\n",
    "- **imgsz**: Input image size (higher = more accurate but slower)\n",
    "- **batch**: Batch size (adjust based on GPU memory)\n",
    "- **device**: GPU device to use (0 for first GPU, 'cpu' for CPU)\n",
    "- **patience**: Early stopping patience (stops if no improvement)\n",
    "- **cache**: Cache images in RAM for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_params = {\n",
    "    'data': dataset_config,           # Path to dataset YAML\n",
    "    'epochs': 300,                     # Number of training epochs\n",
    "    'imgsz': 800,                      # Image size (pixels)\n",
    "    'batch': 16,                       # Batch size (adjust based on GPU memory)\n",
    "    'device': 0,                       # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "    'patience': 100,                   # Early stopping patience\n",
    "    'save': True,                      # Save checkpoints\n",
    "    'cache': True,                     # Cache images in RAM\n",
    "    'cos_lr': True,                    # Use cosine learning rate scheduler\n",
    "    'close_mosaic': 10,                # Disable mosaic augmentation in last N epochs\n",
    "    'box': 10,                         # Box loss weight\n",
    "    'cls': 15.0,                       # Classification loss weight (higher for defect detection)\n",
    "    'dfl': 3.0,                        # Distribution focal loss weight\n",
    "    'flipud': 0.5,                     # Vertical flip probability\n",
    "    'fliplr': 0.5,                     # Horizontal flip probability\n",
    "    'degrees': 0.0,                    # Rotation degrees\n",
    "    'translate': 0.1,                  # Translation\n",
    "    'scale': 0.5,                      # Scale\n",
    "    'project': 'runs/detect',          # Project directory\n",
    "    'name': 'ic_pin_detection',        # Run name\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "Now we'll train the model. This may take a while depending on your hardware and the number of epochs.\n",
    "\n",
    "**Note**: Training progress will be displayed, including:\n",
    "- Loss values (box, cls, dfl)\n",
    "- Metrics (precision, recall, mAP)\n",
    "- Training time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting model training...\\n\")\n",
    "results = model.train(**training_params)\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance\n",
    "\n",
    "After training, evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\\n\")\n",
    "metrics = model.val()\n",
    "\n",
    "# Print key metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"  Box mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  Box mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Results\n",
    "\n",
    "Display training curves and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the results directory\n",
    "results_dir = Path(training_params['project']) / training_params['name']\n",
    "print(f\"Results saved to: {results_dir}\")\n",
    "\n",
    "# Display training results if they exist\n",
    "results_img = results_dir / 'results.png'\n",
    "confusion_matrix = results_dir / 'confusion_matrix.png'\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "if results_img.exists():\n",
    "    img = Image.open(results_img)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Training Results')\n",
    "    axes[0].axis('off')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'Results image not found', ha='center', va='center')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "if confusion_matrix.exists():\n",
    "    img = Image.open(confusion_matrix)\n",
    "    axes[1].imshow(img)\n",
    "    axes[1].set_title('Confusion Matrix')\n",
    "    axes[1].axis('off')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Confusion matrix not found', ha='center', va='center')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Model on Validation Images\n",
    "\n",
    "Run inference on some validation images to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on validation images\n",
    "print(\"Running inference on validation images...\\n\")\n",
    "\n",
    "# Select a few validation images\n",
    "test_images = (list(val_images_path.glob(\"*.jpg\")) + list(val_images_path.glob(\"*.jpeg\")) + list(val_images_path.glob(\"*.png\")))[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img_path in enumerate(test_images):\n",
    "    # Run prediction\n",
    "    results = model(str(img_path), verbose=False)\n",
    "    \n",
    "    # Get the annotated image\n",
    "    annotated = results[0].plot()\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    import cv2\n",
    "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[i].imshow(annotated_rgb)\n",
    "    axes[i].set_title(f\"{img_path.name}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save and Export Model\n",
    "\n",
    "Save the trained model in various formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is automatically saved during training\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "last_model_path = results_dir / 'weights' / 'last.pt'\n",
    "\n",
    "print(f\"Best model saved to: {best_model_path}\")\n",
    "print(f\"Last model saved to: {last_model_path}\")\n",
    "\n",
    "# Load the best model for export\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# Export to ONNX format (optional, for deployment)\n",
    "# Uncomment the line below if you want to export to ONNX\n",
    "# onnx_path = best_model.export(format='onnx')\n",
    "# print(f\"Model exported to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Inference on New Images\n",
    "\n",
    "Use the trained model to detect pins on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "trained_model = YOLO(best_model_path)\n",
    "\n",
    "# Function to run inference on a single image\n",
    "def predict_image(image_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Run inference on an image and display results.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        conf_threshold: Confidence threshold for detections (0-1)\n",
    "    \"\"\"\n",
    "    results = trained_model(image_path, conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    # Display results\n",
    "    annotated = results[0].plot()\n",
    "    import cv2\n",
    "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(annotated_rgb)\n",
    "    plt.title(f\"Predictions on {Path(image_path).name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection summary\n",
    "    boxes = results[0].boxes\n",
    "    if len(boxes) > 0:\n",
    "        print(f\"\\nDetected {len(boxes)} objects:\")\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            class_name = trained_model.names[cls]\n",
    "            print(f\"  - {class_name}: {conf:.2%} confidence\")\n",
    "    else:\n",
    "        print(\"\\nNo objects detected\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Run inference on a validation image\n",
    "if len(val_images) > 0:\n",
    "    sample_image = val_images[0]\n",
    "    print(f\"Running inference on: {sample_image}\\n\")\n",
    "    results = predict_image(sample_image, conf_threshold=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model Summary and Next Steps\n",
    "\n",
    "### Model Information\n",
    "- The trained model can detect and classify IC pins into 4 categories: bent, okay, package, and text\n",
    "- Best model weights are saved and can be loaded for inference\n",
    "- Training results and metrics are available in the runs directory\n",
    "\n",
    "### Next Steps\n",
    "1. **Fine-tune hyperparameters**: Adjust learning rate, batch size, or augmentation settings\n",
    "2. **Add more data**: Collect and annotate more images to improve accuracy\n",
    "3. **Test on real-world data**: Validate performance on images from actual production\n",
    "4. **Deploy the model**: Export to ONNX or other formats for production deployment\n",
    "5. **Monitor performance**: Track model performance over time and retrain as needed\n",
    "\n",
    "### Using the Trained Model\n",
    "```python\n",
    "# Load the trained model\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('runs/detect/ic_pin_detection/weights/best.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model('path/to/image.jpg')\n",
    "results[0].show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}